{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791ce8e2-0e36-450f-a3d5-85658bd6de24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd7d285-61b0-4059-945b-e8761759725d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353b60a5-4d08-4c2d-8d31-9f2ea7a3d9d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b2e22-9ecd-41ad-8f2b-36143f7968c0",
   "metadata": {},
   "source": [
    "### Multi-class probplem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8e8a3-7b84-41a4-a4a0-504de3479100",
   "metadata": {},
   "source": [
    "### Resnet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53450e48-2a50-490b-8dab-ef8db32bb9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 24 15:40:39 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.105.01   Driver Version: 515.105.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "|  0%   23C    P8    14W / 370W |   3020MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 51%   47C    P2   338W / 370W |  18002MiB / 24576MiB |     89%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:A1:00.0 Off |                  N/A |\n",
      "|  0%   23C    P8    16W / 370W |   4254MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:E1:00.0 Off |                  N/A |\n",
      "|  0%   26C    P2   110W / 370W |   4336MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6980a321-0db4-4017-9a37-e7d4cb8f2780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c088bf-c55e-42ba-9d30-dc0ec85225b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1a1c42-7247-4692-8cc1-e620a0a8512b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIABLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30edafdf-6845-4446-aed5-0d0008e8e56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e952232-ad01-4dad-8685-2fc83010c2a7",
   "metadata": {},
   "source": [
    "### Efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b134addb-469a-4110-8c12-deecc9e8fd10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from effnet.efficientnet import efficientnet\n",
    "\n",
    "from utils.trainer import Trainer\n",
    "from data.multi_class_build_data import build_dataloader\n",
    "\n",
    "BATCH_SIZE=8\n",
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, trainset_len, testset_len, NUM_CLASS = build_dataloader(transfrom, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53055a26-6025-4b07-9b99-a04d9335a712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteriation=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f276ea2e-af42-4770-9b65-d533b3f86b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet = efficientnet()\n",
    "effnet.classifier[1] = nn.Linear(1280, NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8c940df9-490a-426c-b31a-76c2e016b9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet = effnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "baea5822-4efa-4e93-9023-b479d2edeae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(effnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1c881-c007-4f1b-8382-ae2470a3a02a",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db05f3b9-db4b-4597-8a2b-9dcb0bab5f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = 'effnet'\n",
    "\n",
    "trainer = Trainer(effnet, \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  optimizer,\n",
    "                  epochs=2,\n",
    "                  path_output='multi_class_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "92089531-75f8-45d1-b960-3271fb067f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]/[2] Epoch starts\n",
      "\t Batch train loss: 1.4173368215560913, accuracy 0.125\n",
      "\t Batch train loss: 0.6500968933105469, accuracy 0.625\n",
      "\t Batch train loss: 0.6747581362724304, accuracy 0.875\n",
      "\t Batch train loss: 1.0785253047943115, accuracy 0.5\n",
      "\t Batch train loss: 0.22702595591545105, accuracy 0.875\n",
      "[1]/[2] End epoch: train loss: 0.693294952304126, val loss: 0.3635874504292515\n",
      "\t Epoch train accuracy: 0.6995078921318054, val accuracy: 0.8468033775633294\n",
      "\n",
      "[2]/[2] Epoch starts\n",
      "\t Batch train loss: 0.24580885469913483, accuracy 0.875\n",
      "\t Batch train loss: 0.37618398666381836, accuracy 0.875\n",
      "\t Batch train loss: 0.242514967918396, accuracy 0.875\n",
      "\t Batch train loss: 0.17320388555526733, accuracy 0.875\n",
      "\t Batch train loss: 0.1986524909734726, accuracy 0.875\n",
      "[2]/[2] End epoch: train loss: 0.2528687315517201, val loss: 0.3794699323693939\n",
      "\t Epoch train accuracy: 0.908406138420105, val accuracy: 0.8584640128669079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c9a2d-e919-4444-8b70-cc6bb554c165",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f855a594-54e2-4dc7-b6fd-bc791a7b39eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet.load_state_dict(torch.load(f'multi_class_output/effnet.pt')['model_state_dict'])\n",
    "effnet = effnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "deae28ef-5529-4a85-be81-38a8c555e0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(effnet, \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  path_output='multi_class_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cb895a39-fd71-4bd5-b145-4d33adbaebfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, preds = trainer.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b62de6c4-1d0f-4eaa-8f23-d9c296d874a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediciton = pd.DataFrame([preds[0].cpu().numpy(), preds[1].cpu().numpy()]).T\n",
    "prediciton.rename = ['labels', 'predictions']\n",
    "\n",
    "prediciton.to_csv('multi_class_output/{name}.csv'.format(name=NAME), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96382bfd-31aa-4a51-864c-8b4c3505917f",
   "metadata": {},
   "source": [
    "### Multi-label problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da4061d-1388-4f19-bf63-ffc7be8a491a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jovyan/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706eb803-c928-4a66-9b3e-190ad38f3d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('sample_labels.csv')\n",
    "data['lables'] = data['Finding Labels'].str.split('|')\n",
    "\n",
    "labels = []\n",
    "for lable in data['lables'].values:\n",
    "    labels.extend(lable)   \n",
    "    \n",
    "labels = pd.DataFrame(labels, columns=['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bbfb2-8ae9-49ba-82b4-b8b0b01b2aa4",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd9ffb-17e4-4969-a385-6386c4c0c7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = 1 / (labels.value_counts()/ labels.shape[0])\n",
    "weights = torch.tensor(weights.reset_index().sort_values(by='labels')[0].values)\n",
    "\n",
    "class WeightedMultilabel(nn.Module):  \n",
    "    def __init__(self, weights: torch.Tensor):  \n",
    "        super(WeightedMultilabel, self).__init__()  \n",
    "        self.cerition = nn.BCEWithLogitsLoss(reduction='none')  \n",
    "        self.weights = weights  \n",
    "  \n",
    "    def forward(self, outputs, targets):  \n",
    "        loss = self.cerition(outputs, targets)  \n",
    "        return (loss * self.weights).mean()  \n",
    "\n",
    "weights = weights.to(device)\n",
    "\n",
    "criteriation = WeightedMultilabel(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e015cea8-8927-4d2f-887d-926156ce1896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.trainer import Trainer\n",
    "from data.multi_label_build_data import build_dataloader\n",
    "from effnet.blocks import SamePadConv2d\n",
    "from effnet.efficientnet import efficientnet\n",
    "\n",
    "\n",
    "BATCH_SIZE=4\n",
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, trainset_len, testset_len, NUM_CLASS = build_dataloader(transfrom, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e804a-518c-4753-8f05-c91d550a935d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del effnet\n",
    "effnet = efficientnet()\n",
    "effnet.classifier[1] = nn.Linear(1280, NUM_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577d9d2-d770-41f9-8d60-4ff7fe1e09bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet.features[0][0] = SamePadConv2d(1, 32, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bac1d1-b6b4-435f-8d87-9c5f21f36819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet = effnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fca761-b6ec-4bb5-a15e-a1335f69b20a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(effnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54a0c9-f461-4299-b9eb-27c524da78f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAME = 'effnet'\n",
    "\n",
    "trainer = Trainer(effnet , \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  optimizer,\n",
    "                  epochs=5,\n",
    "                  path_output='multi_label_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee56368-dde0-4cac-9f45-a013934a1ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]/[5] Epoch starts\n",
      "\t Batch train loss: 0.7092497944831848, accuracy 0.0761904761904762\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/utils/trainer.py:72\u001b[0m, in \u001b[0;36mTrainer.training\u001b[0;34m(self, start, show_treshold)\u001b[0m\n\u001b[1;32m     69\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b_ind, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader):\n\u001b[1;32m     75\u001b[0m     imgs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     76\u001b[0m     imgs, labels \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/work/data/multi_label_build_data.py:64\u001b[0m, in \u001b[0;36mMultiDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(path_img)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img, labels\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:2192\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2184\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2185\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2186\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2187\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2188\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2189\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2190\u001b[0m         )\n\u001b[0;32m-> 2192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05da17-e6d8-43d6-9c0d-dadcf6cd724d",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "60f0444e-e086-499d-9ade-5e127b5b830c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "effnet.load_state_dict(torch.load(f'multi_label_output/effnet.pt')['model_state_dict'])\n",
    "effnet = effnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "66db2f56-f5f1-463a-aa43-b031a51e2359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(effnet , \n",
    "                  criteriation,\n",
    "                  device,\n",
    "                  train_dataloader,\n",
    "                  test_dataloader,\n",
    "                  trainset_len,\n",
    "                  testset_len,\n",
    "                  path_output='multi_label_output/{name}.pt'.format(name=NAME),\n",
    "                  multi_label=True\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f5f27dfa-0456-4dfc-b276-58905da88210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, preds = trainer.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4a79b654-c80f-4fb5-b857-db67e7629118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preds[0].cpu().numpy()).to_csv('multi_label_output/true_{name}.csv'.format(name=NAME), index=False)\n",
    "pd.DataFrame(preds[1].cpu().numpy()).to_csv('multi_label_output/pred_{name}.csv'.format(name=NAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581be29-5bd2-4038-b1bf-d8a318fcf499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
